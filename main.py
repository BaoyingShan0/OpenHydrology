#!/usr/bin/env python3
"""
æ°´åˆ©å¤šæ¨¡æ€æ•°æ®å¤„ç†å·¥å…·ä¸»å…¥å£
OpenHydrology Data Processing Tool

ä½¿ç”¨æ–¹æ³•:
    python main.py --input /path/to/files --output /path/to/output
    python main.py --config config.yaml --input /path/to/directory --recursive
    python main.py --help
"""

import argparse
import sys
import os
from pathlib import Path
from typing import Optional, List
from loguru import logger

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.config import config_manager
from src.utils import setup_logging
from src.skills.pipeline import HydroDataPipeline


def setup_argument_parser() -> argparse.ArgumentParser:
    """è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="æ°´åˆ©å¤šæ¨¡æ€æ•°æ®å¤„ç†å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # å¤„ç†å•ä¸ªæ–‡ä»¶
  python main.py --input data/report.pdf --output processed_data.json
  
  # å¤„ç†ç›®å½•ï¼ˆé€’å½’ï¼‰
  python main.py --input ./documents --output results/ --recursive
  
  # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
  python main.py --config custom_config.yaml --input ./data --output output.json
  
  # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
  python main.py --input ./data --report-only
        """
    )
    
    # è¾“å…¥å‚æ•°
    parser.add_argument(
        "--input", "-i",
        type=str,
        required=True,
        help="è¾“å…¥æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„"
    )
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument(
        "--output", "-o",
        type=str,
        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼š./output/processed_data_TIMESTAMP.jsonï¼‰"
    )
    
    # é…ç½®æ–‡ä»¶
    parser.add_argument(
        "--config", "-c",
        type=str,
        help="è‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    
    # é€’å½’å¤„ç†
    parser.add_argument(
        "--recursive", "-r",
        action="store_true",
        help="é€’å½’å¤„ç†å­ç›®å½•"
    )
    
    # æ‰¹é‡å¤§å°
    parser.add_argument(
        "--batch-size",
        type=int,
        help="æ‰¹å¤„ç†å¤§å°ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶è®¾ç½®ï¼‰"
    )
    
    # å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°
    parser.add_argument(
        "--workers", "-w",
        type=int,
        help="å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶è®¾ç½®ï¼‰"
    )
    
    # æ—¥å¿—çº§åˆ«
    parser.add_argument(
        "--log-level",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="INFO",
        help="æ—¥å¿—çº§åˆ«"
    )
    
    # æ—¥å¿—æ–‡ä»¶
    parser.add_argument(
        "--log-file",
        type=str,
        help="æ—¥å¿—æ–‡ä»¶è·¯å¾„"
    )
    
    # ä»…ç”ŸæˆæŠ¥å‘Š
    parser.add_argument(
        "--report-only",
        action="store_true",
        help="ä»…ç”Ÿæˆå¤„ç†æŠ¥å‘Šï¼Œä¸æ‰§è¡Œå¤„ç†"
    )
    
    # ç¦ç”¨æ£€æŸ¥ç‚¹
    parser.add_argument(
        "--no-checkpoint",
        action="store_true",
        help="ç¦ç”¨æ£€æŸ¥ç‚¹åŠŸèƒ½"
    )
    
    # é”™è¯¯å¤„ç†æ¨¡å¼
    parser.add_argument(
        "--on-error",
        choices=["skip", "stop", "retry"],
        default="skip",
        help="é”™è¯¯å¤„ç†æ¨¡å¼"
    )
    
    # æ˜¾ç¤ºæ”¯æŒçš„æ ¼å¼
    parser.add_argument(
        "--list-formats",
        action="store_true",
        help="æ˜¾ç¤ºæ”¯æŒçš„æ–‡ä»¶æ ¼å¼å¹¶é€€å‡º"
    )
    
    # ç‰ˆæœ¬ä¿¡æ¯
    parser.add_argument(
        "--version",
        action="version",
        version="%(prog)s 1.0.0"
    )
    
    return parser


def setup_custom_config(args) -> bool:
    """è®¾ç½®è‡ªå®šä¹‰é…ç½®"""
    try:
        # åŠ è½½è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
        if args.config:
            if not os.path.exists(args.config):
                logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
                return False
            
            # é‡æ–°åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
            global config_manager
            from src.config import ConfigManager
            config_manager = ConfigManager(args.config)
            logger.info(f"åŠ è½½è‡ªå®šä¹‰é…ç½®æ–‡ä»¶: {args.config}")
        
        # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
        if args.batch_size:
            config_manager.set("pipeline.batch_size", args.batch_size)
        
        if args.workers:
            config_manager.set("pipeline.max_workers", args.workers)
        
        if args.no_checkpoint:
            config_manager.set("pipeline.checkpoint_enabled", False)
        
        if args.on_error:
            config_manager.set("pipeline.error_handling", args.on_error)
        
        return True
        
    except Exception as e:
        logger.error(f"é…ç½®è®¾ç½®å¤±è´¥: {e}")
        return False


def validate_input_path(input_path: str) -> bool:
    """éªŒè¯è¾“å…¥è·¯å¾„"""
    path = Path(input_path)
    
    if not path.exists():
        logger.error(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
        return False
    
    if not (path.is_file() or path.is_dir()):
        logger.error(f"è¾“å…¥è·¯å¾„ä¸æ˜¯æœ‰æ•ˆçš„æ–‡ä»¶æˆ–ç›®å½•: {input_path}")
        return False
    
    return True


def get_default_output_path() -> str:
    """è·å–é»˜è®¤è¾“å‡ºè·¯å¾„"""
    from src.utils import get_timestamp
    output_dir = Path(config_manager.get('global.output_dir', './output'))
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = get_timestamp()
    return str(output_dir / f"processed_data_{timestamp}.json")


def process_data(pipeline: HydroDataPipeline, input_path: str, 
                output_path: str, recursive: bool = False) -> bool:
    """å¤„ç†æ•°æ®"""
    input_path_obj = Path(input_path)
    
    try:
        if input_path_obj.is_file():
            # å¤„ç†å•ä¸ªæ–‡ä»¶
            logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {input_path}")
            result = pipeline.process_files([input_path], output_path)
        else:
            # å¤„ç†ç›®å½•
            logger.info(f"å¼€å§‹å¤„ç†ç›®å½•: {input_path} (é€’å½’: {recursive})")
            result = pipeline.process_directory(input_path, recursive, output_path)
        
        # å¤„ç†ç»“æœ
        if result.success:
            logger.info("æ•°æ®å¤„ç†å®Œæˆ!")
            logger.info(f"å¤„ç†æ—¶é—´: {result.processing_time:.2f}ç§’")
            
            if result.data:
                stats = result.data.get_statistics()
                logger.info(f"ç”Ÿæˆæ•°æ®å—: {stats['total_chunks']}")
                logger.info(f"ç”Ÿæˆé—®ç­”å¯¹: {stats['total_qa_pairs']}")
                logger.info(f"æ€»å­—ç¬¦æ•°: {stats['total_characters']}")
            
            return True
        else:
            logger.error(f"æ•°æ®å¤„ç†å¤±è´¥: {result.error_message}")
            return False
            
    except Exception as e:
        logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
        return False


def generate_report(pipeline: HydroDataPipeline, input_path: str, 
                   output_path: Optional[str] = None) -> None:
    """ç”Ÿæˆå¤„ç†æŠ¥å‘Š"""
    report = pipeline.get_processing_report()
    
    if output_path:
        report_file = output_path
    else:
        from src.utils import get_timestamp
        report_file = f"./processing_report_{get_timestamp()}.json"
    
    try:
        import json
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"å¤„ç†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # æ˜¾ç¤ºç®€è¦ä¿¡æ¯
        print("\n" + "="*50)
        print("å¤„ç†æŠ¥å‘Šæ‘˜è¦")
        print("="*50)
        print(f"å¤„ç†çš„æŠ€èƒ½: {', '.join(report['skills'])}")
        print(f"æ‰¹å¤„ç†å¤§å°: {report['config']['batch_size']}")
        print(f"å¹¶è¡Œå·¥ä½œçº¿ç¨‹: {report['config']['max_workers']}")
        print(f"DataFlowé›†æˆ: {'å¯ç”¨' if report['dataflow_enabled'] else 'ç¦ç”¨'}")
        
        if report['statistics']['total_files'] > 0:
            print(f"å¤„ç†æ–‡ä»¶æ•°: {report['statistics']['processed_files']}/{report['statistics']['total_files']}")
            print(f"å¤„ç†æ•°æ®å—æ•°: {report['statistics']['processed_chunks']}")
        
        print("="*50)
        
    except Exception as e:
        logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")


def list_supported_formats(pipeline: HydroDataPipeline) -> None:
    """æ˜¾ç¤ºæ”¯æŒçš„æ–‡ä»¶æ ¼å¼"""
    formats = pipeline.get_supported_file_formats()
    
    print("\næ”¯æŒçš„æ–‡ä»¶æ ¼å¼:")
    print("-" * 30)
    for fmt in formats:
        print(f"  .{fmt}")
    print("-" * 30)
    print(f"å…±æ”¯æŒ {len(formats)} ç§æ ¼å¼")


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = setup_argument_parser()
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(args.log_level, args.log_file)
    
    # æ˜¾ç¤ºæ”¯æŒçš„æ ¼å¼å¹¶é€€å‡º
    if args.list_formats:
        # åˆ›å»ºä¸´æ—¶pipelineå®ä¾‹æ¥è·å–æ”¯æŒçš„æ ¼å¼
        try:
            pipeline = HydroDataPipeline()
            list_supported_formats(pipeline)
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
            sys.exit(1)
        sys.exit(0)
    
    # éªŒè¯è¾“å…¥è·¯å¾„
    if not validate_input_path(args.input):
        sys.exit(1)
    
    # è®¾ç½®é…ç½®
    if not setup_custom_config(args):
        sys.exit(1)
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    config_manager.create_directories()
    
    try:
        # åˆå§‹åŒ–pipeline
        pipeline = HydroDataPipeline()
        
        # å¦‚æœåªæ˜¯ç”ŸæˆæŠ¥å‘Š
        if args.report_only:
            generate_report(pipeline, args.input, args.output)
            sys.exit(0)
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        output_path = args.output if args.output else get_default_output_path()
        
        # å¤„ç†æ•°æ®
        success = process_data(pipeline, args.input, output_path, args.recursive)
        
        if success:
            # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
            generate_report(pipeline, args.input)
            
            print("\nğŸ‰ æ•°æ®å¤„ç†æˆåŠŸå®Œæˆ!")
            print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
            
            sys.exit(0)
        else:
            print("\nâŒ æ•°æ®å¤„ç†å¤±è´¥!")
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­å¤„ç†")
        print("\nâ¹ï¸  å¤„ç†å·²ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        print(f"\nğŸ’¥ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()