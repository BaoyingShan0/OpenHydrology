# æ°´åˆ©å¤šæ¨¡æ€æ•°æ®å¤„ç†å·¥å…·

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

ä¸€ä¸ªä¸“é—¨ä¸ºæ°´åˆ©å¤§æ¨¡å‹å‡†å¤‡è®­ç»ƒæ•°æ®çš„Claude Skillå·¥å…·ï¼Œèƒ½å¤Ÿè‡ªåŠ¨å¤„ç†å¤šç§æ ¼å¼çš„æ°´åˆ©æ•°æ®ï¼ŒåŒ…æ‹¬PDFæ–‡æ¡£ã€çº¯æ–‡æœ¬ã€ä½è´¨é‡é—®ç­”ç­‰ï¼Œä»ä¸­è§£æã€æ¸…æ´—ã€å¢å¼ºå¹¶è¯„ä¼°é«˜è´¨é‡æ•°æ®ã€‚

## ğŸŒŸ ä¸»è¦ç‰¹æ€§

### ğŸ”„ å®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹
- **HydroData-Parser**: æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼è§£æï¼ˆPDFã€TXTã€JSONã€CSVã€MDï¼‰
- **HydroData-Cleaner**: æ™ºèƒ½æ•°æ®æ¸…æ´—å’Œå»å™ª
- **HydroData-Enhancer**: æ•°æ®å¢å¼ºå’Œé—®ç­”å¯¹ç”Ÿæˆ
- **HydroData-Evaluator**: å¤šç»´åº¦è´¨é‡è¯„ä¼°
- **HydroData-Pipeline**: å®Œæ•´æµç¨‹æ§åˆ¶å’Œåè°ƒ

### ğŸš€ å¼ºå¤§çš„åŠŸèƒ½ç‰¹æ€§
- âœ… **å¤šè¯­è¨€æ”¯æŒ**: ä¸­æ–‡ã€è‹±æ–‡è‡ªåŠ¨è¯†åˆ«å’Œå¤„ç†
- âœ… **æ™ºèƒ½å»é‡**: åŸºäºå“ˆå¸Œå’Œç›¸ä¼¼åº¦çš„é‡å¤æ•°æ®æ£€æµ‹
- âœ… **ä¸“ä¸šæœ¯è¯­**: æ°´åˆ©é¢†åŸŸçŸ¥è¯†åº“å’Œä¸“ä¸šæœ¯è¯­æå–
- âœ… **é—®ç­”ç”Ÿæˆ**: è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡é—®ç­”å¯¹
- âœ… **è´¨é‡è¯„ä¼°**: å®Œæ•´æ€§ã€ç›¸å…³æ€§ã€ä¸€è‡´æ€§ã€å¤šæ ·æ€§å¤šç»´åº¦è¯„ä¼°
- âœ… **å¹¶è¡Œå¤„ç†**: æ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†æå‡æ•ˆç‡
- âœ… **æ£€æŸ¥ç‚¹**: æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œå¤„ç†å¤§æ•°æ®æ›´å®‰å…¨
- âœ… **DataFlowé›†æˆ**: æ”¯æŒDataFlowå·¥ä½œæµå¼•æ“

### ğŸ“Š æ”¯æŒçš„æ•°æ®æ ¼å¼
- ğŸ“„ **PDFæ–‡æ¡£**: è‡ªåŠ¨æå–æ–‡æœ¬ã€è¡¨æ ¼å†…å®¹
- ğŸ“ **çº¯æ–‡æœ¬**: æ”¯æŒå¤šç§ç¼–ç è‡ªåŠ¨æ£€æµ‹
- ğŸ“Š **JSONç»“æ„**: é€’å½’è§£æåµŒå¥—æ•°æ®ç»“æ„
- ğŸ“ˆ **CSVè¡¨æ ¼**: æ™ºèƒ½è§£æè¡¨æ ¼æ•°æ®
- ğŸ“‘ **Markdown**: æ”¯æŒMarkdownæ ¼å¼æ–‡æ¡£

## ğŸ› ï¸ å®‰è£…å’Œä½¿ç”¨

### ç¯å¢ƒè¦æ±‚
- Python 3.8+
- æ¨èä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ

### å®‰è£…ä¾èµ–
```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd OpenHydrology_data

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### å¯é€‰ä¾èµ–
```bash
# PDFå¤„ç†æ”¯æŒ
pip install PyPDF2 pdfplumber

# é«˜çº§NLPåŠŸèƒ½
pip install spacy transformers
python -m spacy download en_core_web_sm

# ä¸­æ–‡åˆ†è¯æ”¯æŒ
pip install jieba

# è¯­è¨€æ£€æµ‹
pip install langdetect

# æ•°æ®ç§‘å­¦å·¥å…·
pip install scikit-learn pandas numpy

# é«˜çº§æ–‡æœ¬å¤„ç†
pip install chardet
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬ä½¿ç”¨
```bash
# å¤„ç†å•ä¸ªæ–‡ä»¶
python main.py --input data/report.pdf --output result.json

# å¤„ç†æ•´ä¸ªç›®å½•
python main.py --input ./documents --output results.json --recursive

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
python main.py --config custom_config.yaml --input ./data --output result.json
```

### 2. é«˜çº§é€‰é¡¹
```bash
# è®¾ç½®æ‰¹å¤„ç†å¤§å°å’Œå·¥ä½œçº¿ç¨‹
python main.py --input ./data --batch-size 50 --workers 8

# åªç”ŸæˆæŠ¥å‘Šä¸å¤„ç†
python main.py --input ./data --report-only

# æŸ¥çœ‹æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
python main.py --list-formats
```

### 3. ç¼–ç¨‹æ¥å£ä½¿ç”¨
```python
from src.skills.pipeline import HydroDataPipeline
from src.config import config_manager

# åˆå§‹åŒ–pipeline
pipeline = HydroDataPipeline()

# å¤„ç†æ–‡ä»¶
result = pipeline.process_files("data/report.pdf", "output.json")

# å¤„ç†ç›®å½•
result = pipeline.process_directory("./documents", recursive=True)

# è·å–å¤„ç†æŠ¥å‘Š
report = pipeline.get_processing_report()
```

## ğŸ“‹ é…ç½®æ–‡ä»¶è¯´æ˜

ä¸»è¦é…ç½®æ–‡ä»¶ `config/hydro_config.yaml`:

```yaml
# å…¨å±€è®¾ç½®
global:
  log_level: INFO
  output_dir: ./output
  temp_dir: ./temp
  max_workers: 4

# è§£æå™¨é…ç½®
parser:
  supported_formats: [pdf, txt, json, csv, md]
  text_settings:
    chunk_size: 1000
    overlap: 100
  pdf_settings:
    extract_tables: true
    min_confidence: 0.8

# æ¸…æ´—å™¨é…ç½®
cleaner:
  remove_duplicates: true
  normalize_whitespace: true
  min_text_length: 10

# å¢å¼ºå™¨é…ç½®
enhancer:
  enable_qa_generation: true
  enable_term_extraction: true
  
# è¯„ä¼°å™¨é…ç½®
evaluator:
  quality_metrics: [completeness, relevance, consistency, diversity]
  thresholds:
    min_quality_score: 0.7

# æµç¨‹æ§åˆ¶é…ç½®
pipeline:
  batch_size: 100
  parallel_processing: true
  checkpoint_enabled: true
```

## ğŸ“Š å¤„ç†ç»“æœæ ¼å¼

å¤„ç†åçš„æ•°æ®ä¿å­˜åœ¨JSONæ ¼å¼ä¸­ï¼ŒåŒ…å«ä»¥ä¸‹ç»“æ„ï¼š

```json
{
  "id": "processed_data_id",
  "name": "processed_data_20231214_120000",
  "description": "å¤„ç†æ•°æ®çš„æè¿°",
  "statistics": {
    "total_chunks": 150,
    "total_qa_pairs": 75,
    "total_characters": 50000,
    "data_types": {"pdf": 100, "text": 50},
    "languages": {"zh": 120, "en": 30}
  },
  "chunks": [
    {
      "id": "chunk_id",
      "content": "å¤„ç†åçš„æ–‡æœ¬å†…å®¹",
      "data_type": "text",
      "language": "zh",
      "extra_data": {
        "extracted_terms": [...],
        "quality_score": {...},
        "generated_qa": [...]
      }
    }
  ],
  "qa_pairs": [
    {
      "question": "ä»€ä¹ˆæ˜¯æ°´æ–‡ï¼Ÿ",
      "answer": "æ°´æ–‡æ˜¯ç ”ç©¶æ°´çš„å„ç§ç°è±¡å’Œè§„å¾‹çš„ç§‘å­¦...",
      "context": "ç›¸å…³ä¸Šä¸‹æ–‡",
      "domain": "æ°´æ–‡å­¦",
      "confidence": 0.85
    }
  ]
}
```

## ğŸ”§ æ ¸å¿ƒç»„ä»¶è¯¦è§£

### HydroData-Parser æ•°æ®è§£æå™¨

è´Ÿè´£è§£æä¸åŒæ ¼å¼çš„åŸå§‹æ•°æ®æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§ç¼–ç æ£€æµ‹å’Œè¯­è¨€è¯†åˆ«ã€‚

**ä¸»è¦åŠŸèƒ½:**
- å¤šæ ¼å¼æ–‡ä»¶è§£æï¼ˆPDFã€TXTã€JSONã€CSVã€MDï¼‰
- è‡ªåŠ¨ç¼–ç æ£€æµ‹
- å¤šè¯­è¨€æ”¯æŒ
- å¤§æ–‡ä»¶åˆ†å—å¤„ç†
- å…ƒæ•°æ®æå–

**ä½¿ç”¨ç¤ºä¾‹:**
```python
from src.skills.parser import HydroDataParser

parser = HydroDataParser()
chunks = parser.parse_file("data/report.pdf")
# è¿”å› DataChunk å¯¹è±¡åˆ—è¡¨
```

### HydroData-Cleaner æ•°æ®æ¸…æ´—å™¨

å»é™¤æ•°æ®å™ªå£°ï¼Œæ ‡å‡†åŒ–æ ¼å¼ï¼Œæå‡æ•°æ®è´¨é‡ã€‚

**ä¸»è¦åŠŸèƒ½:**
- é‡å¤æ•°æ®æ£€æµ‹å’Œå»é™¤
- æ–‡æœ¬æ ¼å¼æ ‡å‡†åŒ–
- ç‰¹æ®Šå­—ç¬¦å¤„ç†
- è´¨é‡è¿‡æ»¤
- å¤šè¯­è¨€æ¸…æ´—

**ä½¿ç”¨ç¤ºä¾‹:**
```python
from src.skills.cleaner import HydroDataCleaner

cleaner = HydroDataCleaner()
cleaned_chunks = cleaner.process_batch(chunks)
```

### HydroData-Enhancer æ•°æ®å¢å¼ºå™¨

ä¸°å¯Œæ•°æ®å†…å®¹ï¼Œç”Ÿæˆé—®ç­”å¯¹ï¼Œæå–ä¸“ä¸šæœ¯è¯­ã€‚

**ä¸»è¦åŠŸèƒ½:**
- ä¸“ä¸šæœ¯è¯­æå–
- é—®ç­”å¯¹è‡ªåŠ¨ç”Ÿæˆ
- çŸ¥è¯†å›¾è°±æ„å»º
- é¢†åŸŸçŸ¥è¯†å…³è”
- å¤šæ¨¡æ€å¢å¼º

**ä½¿ç”¨ç¤ºä¾‹:**
```python
from src.skills.enhancer import HydroDataEnhancer

enhancer = HydroDataEnhancer()
enhanced_chunks = enhancer.process_batch(cleaned_chunks)
```

### HydroData-Evaluator æ•°æ®è¯„ä¼°å™¨

å¤šç»´åº¦è¯„ä¼°æ•°æ®è´¨é‡ï¼Œæä¾›æ”¹è¿›å»ºè®®ã€‚

**è¯„ä¼°ç»´åº¦:**
- **å®Œæ•´æ€§**: å†…å®¹é•¿åº¦ã€ç»“æ„ã€ä¿¡æ¯å¯†åº¦
- **ç›¸å…³æ€§**: æ°´åˆ©é¢†åŸŸç›¸å…³æ€§ã€ä¸“ä¸šæœ¯è¯­æ¯”ä¾‹
- **ä¸€è‡´æ€§**: è¯­è¨€ä¸€è‡´æ€§ã€æœ¯è¯­ä½¿ç”¨ä¸€è‡´æ€§
- **å¤šæ ·æ€§**: è¯æ±‡å¤šæ ·æ€§ã€å¥å¼å¤šæ ·æ€§ã€ä¸»é¢˜å¤šæ ·æ€§

**ä½¿ç”¨ç¤ºä¾‹:**
```python
from src.skills.evaluator import HydroDataEvaluator

evaluator = HydroDataEvaluator()
evaluated_chunks = evaluator.process_batch(enhanced_chunks)
report = evaluator.get_evaluation_report()
```

### HydroData-Pipeline æµç¨‹æ§åˆ¶å™¨

åè°ƒæ‰€æœ‰ç»„ä»¶ï¼Œæä¾›å®Œæ•´çš„å¤„ç†æµç¨‹ã€‚

**ä¸»è¦åŠŸèƒ½:**
- æµç¨‹ç¼–æ’å’Œåè°ƒ
- æ‰¹é‡å’Œå¹¶è¡Œå¤„ç†
- æ£€æŸ¥ç‚¹ç®¡ç†
- é”™è¯¯å¤„ç†å’Œæ¢å¤
- DataFlowå·¥ä½œæµé›†æˆ

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ç¡¬ä»¶ä¼˜åŒ–
- **CPU**: å¤šæ ¸å¤„ç†å™¨ï¼Œæ¨è8æ ¸ä»¥ä¸Š
- **å†…å­˜**: 16GBä»¥ä¸Šï¼Œå¤„ç†å¤§æ–‡ä»¶æ—¶å»ºè®®32GB
- **å­˜å‚¨**: SSDç¡¬ç›˜ï¼Œæå‡I/Oæ€§èƒ½

### 2. è½¯ä»¶é…ç½®
- **å¹¶è¡Œå¤„ç†**: æ ¹æ®CPUæ ¸å¿ƒæ•°è®¾ç½®åˆé€‚çš„workeræ•°é‡
- **æ‰¹å¤„ç†å¤§å°**: æ ¹æ®å†…å­˜å¤§å°è°ƒæ•´batch_size
- **æ£€æŸ¥ç‚¹**: å¤„ç†å¤§æ•°æ®æ—¶å¯ç”¨æ£€æŸ¥ç‚¹åŠŸèƒ½

### 3. é…ç½®è°ƒä¼˜
```yaml
pipeline:
  batch_size: 200        # å¢å¤§æ‰¹å¤„ç†å¤§å°
  max_workers: 8         # å¢åŠ å¹¶è¡Œçº¿ç¨‹
  parallel_processing: true
  
global:
  max_workers: 8         # å…¨å±€å¹¶è¡Œè®¾ç½®
```

## ğŸ› å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### Q1: PDFè§£æå¤±è´¥
**åŸå› **: ç¼ºå°‘PDFå¤„ç†åº“æˆ–PDFæ–‡ä»¶æŸå
**è§£å†³**: 
```bash
pip install PyPDF2 pdfplumber
# æ£€æŸ¥PDFæ–‡ä»¶æ˜¯å¦å¯æ­£å¸¸æ‰“å¼€
```

### Q2: ä¸­æ–‡æ˜¾ç¤ºä¹±ç 
**åŸå› **: ç¼–ç æ£€æµ‹å¤±è´¥
**è§£å†³**: 
```yaml
parser:
  text_settings:
    encoding_detection: true
```

### Q3: å†…å­˜ä¸è¶³
**åŸå› **: å¤„ç†å¤§æ–‡ä»¶æ—¶å†…å­˜å ç”¨è¿‡é«˜
**è§£å†³**:
```yaml
pipeline:
  batch_size: 50        # å‡å°æ‰¹å¤„ç†å¤§å°
  max_workers: 2        # å‡å°‘å¹¶è¡Œçº¿ç¨‹
```

### Q4: å¤„ç†é€Ÿåº¦æ…¢
**åŸå› **: å•çº¿ç¨‹å¤„ç†æˆ–æ•°æ®é‡å¤§
**è§£å†³**:
```yaml
pipeline:
  parallel_processing: true
  max_workers: 8
```

## ğŸ“š APIå‚è€ƒ

### HydroDataPipeline

ä¸»è¦çš„æ•°æ®å¤„ç†æµç¨‹æ§åˆ¶ç±»ã€‚

**æ–¹æ³•:**
- `process_files(file_paths, output_path)` - å¤„ç†æ–‡ä»¶åˆ—è¡¨
- `process_directory(directory_path, recursive, output_path)` - å¤„ç†ç›®å½•
- `get_processing_report()` - è·å–å¤„ç†æŠ¥å‘Š
- `get_supported_file_formats()` - è·å–æ”¯æŒçš„æ ¼å¼

### DataChunk

æ•°æ®å—åŸºç±»ï¼ŒåŒ…å«å¤„ç†çš„åŸºæœ¬å•å…ƒã€‚

**å±æ€§:**
- `id`: å”¯ä¸€æ ‡è¯†ç¬¦
- `content`: æ–‡æœ¬å†…å®¹
- `data_type`: æ•°æ®ç±»å‹ï¼ˆPDFã€TEXTç­‰ï¼‰
- `language`: è¯­è¨€ç±»å‹
- `extra_data`: é¢å¤–æ•°æ®ï¼ˆæœ¯è¯­ã€è´¨é‡è¯„åˆ†ç­‰ï¼‰

### QualityScore

è´¨é‡è¯„åˆ†å¯¹è±¡ã€‚

**å±æ€§:**
- `overall_score`: æ€»ä½“è¯„åˆ†
- `completeness_score`: å®Œæ•´æ€§è¯„åˆ†
- `relevance_score`: ç›¸å…³æ€§è¯„åˆ†
- `consistency_score`: ä¸€è‡´æ€§è¯„åˆ†
- `diversity_score`: å¤šæ ·æ€§è¯„åˆ†

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç å’Œæ”¹è¿›å»ºè®®ï¼

### å¼€å‘ç¯å¢ƒè®¾ç½®
```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd OpenHydrology_data

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ–
venv\\Scripts\\activate   # Windows

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### è¿è¡Œæµ‹è¯•
```bash
# è¿è¡Œå•å…ƒæµ‹è¯•
python -m pytest tests/

# è¿è¡Œä»£ç è´¨é‡æ£€æŸ¥
flake8 src/
black src/
```

### æäº¤è§„èŒƒ
- feat: æ–°åŠŸèƒ½
- fix: ä¿®å¤bug
- docs: æ–‡æ¡£æ›´æ–°
- style: ä»£ç æ ¼å¼è°ƒæ•´
- refactor: ä»£ç é‡æ„
- test: æµ‹è¯•ç›¸å…³
- chore: æ„å»ºè¿‡ç¨‹æˆ–è¾…åŠ©å·¥å…·çš„å˜åŠ¨

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢

- [DataFlow](https://github.com/OpenDCAI/DataFlow) - å·¥ä½œæµå¼•æ“æ”¯æŒ
- [spaCy](https://spacy.io/) - è‡ªç„¶è¯­è¨€å¤„ç†
- [Transformers](https://huggingface.co/transformers/) - é¢„è®­ç»ƒæ¨¡å‹
- [jieba](https://github.com/fxsjy/jieba) - ä¸­æ–‡åˆ†è¯

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- ğŸ“§ Email: [your-email@example.com]
- ğŸ› Issues: [GitHub Issues](https://github.com/your-repo/issues)
- ğŸ“– æ–‡æ¡£: [é¡¹ç›®æ–‡æ¡£](https://your-docs-site.com)

---

**è®©æ°´åˆ©æ•°æ®å¤„ç†æ›´ç®€å•ï¼Œè®©AIç†è§£æ°´åˆ©ä¸–ç•Œï¼** ğŸŒŠ